[2022-05-23 21:06:30,713] {processor.py:153} INFO - Started process (PID=170) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:06:30,714] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:06:30,714] {logging_mixin.py:115} INFO - [2022-05-23 21:06:30,714] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:07:00,715] {logging_mixin.py:115} INFO - [2022-05-23 21:07:00,715] {timeout.py:67} ERROR - Process timed out, PID: 170
[2022-05-23 21:07:00,717] {logging_mixin.py:115} INFO - [2022-05-23 21:07:00,716] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 170
[2022-05-23 21:07:00,718] {logging_mixin.py:115} INFO - [2022-05-23 21:07:00,718] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:07:00,718] {logging_mixin.py:115} INFO - [2022-05-23 21:07:00,718] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 170

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:07:00,718] {logging_mixin.py:115} INFO - [2022-05-23 21:07:00,718] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:07:00,719] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:07:00,736] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.025 seconds
[2022-05-23 21:07:30,827] {processor.py:153} INFO - Started process (PID=420) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:07:30,828] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:07:30,829] {logging_mixin.py:115} INFO - [2022-05-23 21:07:30,829] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:08:00,831] {logging_mixin.py:115} INFO - [2022-05-23 21:08:00,831] {timeout.py:67} ERROR - Process timed out, PID: 420
[2022-05-23 21:08:00,833] {logging_mixin.py:115} INFO - [2022-05-23 21:08:00,831] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 420
[2022-05-23 21:08:00,833] {logging_mixin.py:115} INFO - [2022-05-23 21:08:00,833] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:08:00,835] {logging_mixin.py:115} INFO - [2022-05-23 21:08:00,834] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 420

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:08:00,836] {logging_mixin.py:115} INFO - [2022-05-23 21:08:00,835] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:08:00,837] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:08:00,863] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.041 seconds
[2022-05-23 21:08:30,978] {processor.py:153} INFO - Started process (PID=662) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:08:30,979] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:08:30,979] {logging_mixin.py:115} INFO - [2022-05-23 21:08:30,979] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:09:00,981] {logging_mixin.py:115} INFO - [2022-05-23 21:09:00,981] {timeout.py:67} ERROR - Process timed out, PID: 662
[2022-05-23 21:09:00,983] {logging_mixin.py:115} INFO - [2022-05-23 21:09:00,981] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 662
[2022-05-23 21:09:00,984] {logging_mixin.py:115} INFO - [2022-05-23 21:09:00,983] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:09:00,985] {logging_mixin.py:115} INFO - [2022-05-23 21:09:00,984] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 662

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:09:00,986] {logging_mixin.py:115} INFO - [2022-05-23 21:09:00,986] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:09:00,986] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:09:01,011] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.036 seconds
[2022-05-23 21:09:31,103] {processor.py:153} INFO - Started process (PID=912) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:09:31,103] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:09:31,104] {logging_mixin.py:115} INFO - [2022-05-23 21:09:31,104] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:10:01,105] {logging_mixin.py:115} INFO - [2022-05-23 21:10:01,104] {timeout.py:67} ERROR - Process timed out, PID: 912
[2022-05-23 21:10:01,107] {logging_mixin.py:115} INFO - [2022-05-23 21:10:01,105] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 912
[2022-05-23 21:10:01,108] {logging_mixin.py:115} INFO - [2022-05-23 21:10:01,108] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:10:01,109] {logging_mixin.py:115} INFO - [2022-05-23 21:10:01,108] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 912

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:10:01,110] {logging_mixin.py:115} INFO - [2022-05-23 21:10:01,109] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:10:01,110] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:10:01,134] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.032 seconds
[2022-05-23 21:10:31,284] {processor.py:153} INFO - Started process (PID=1155) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:10:31,284] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:10:31,285] {logging_mixin.py:115} INFO - [2022-05-23 21:10:31,285] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:11:01,286] {logging_mixin.py:115} INFO - [2022-05-23 21:11:01,286] {timeout.py:67} ERROR - Process timed out, PID: 1155
[2022-05-23 21:11:01,288] {logging_mixin.py:115} INFO - [2022-05-23 21:11:01,286] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 1155
[2022-05-23 21:11:01,289] {logging_mixin.py:115} INFO - [2022-05-23 21:11:01,289] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:11:01,290] {logging_mixin.py:115} INFO - [2022-05-23 21:11:01,289] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 1155

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:11:01,291] {logging_mixin.py:115} INFO - [2022-05-23 21:11:01,291] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:11:01,292] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:11:01,322] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.041 seconds
[2022-05-23 21:11:31,838] {processor.py:153} INFO - Started process (PID=1397) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:11:31,838] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:11:31,839] {logging_mixin.py:115} INFO - [2022-05-23 21:11:31,839] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:12:01,841] {logging_mixin.py:115} INFO - [2022-05-23 21:12:01,840] {timeout.py:67} ERROR - Process timed out, PID: 1397
[2022-05-23 21:12:01,843] {logging_mixin.py:115} INFO - [2022-05-23 21:12:01,841] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 1397
[2022-05-23 21:12:01,843] {logging_mixin.py:115} INFO - [2022-05-23 21:12:01,843] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:12:01,845] {logging_mixin.py:115} INFO - [2022-05-23 21:12:01,844] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 1397

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:12:01,846] {logging_mixin.py:115} INFO - [2022-05-23 21:12:01,846] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:12:01,847] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:12:01,859] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.024 seconds
[2022-05-23 21:12:31,989] {processor.py:153} INFO - Started process (PID=1645) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:12:31,989] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:12:31,990] {logging_mixin.py:115} INFO - [2022-05-23 21:12:31,989] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:13:01,990] {logging_mixin.py:115} INFO - [2022-05-23 21:13:01,990] {timeout.py:67} ERROR - Process timed out, PID: 1645
[2022-05-23 21:13:01,991] {logging_mixin.py:115} INFO - [2022-05-23 21:13:01,990] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 1645
[2022-05-23 21:13:01,991] {logging_mixin.py:115} INFO - [2022-05-23 21:13:01,991] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:13:01,992] {logging_mixin.py:115} INFO - [2022-05-23 21:13:01,992] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 1645

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:13:01,993] {logging_mixin.py:115} INFO - [2022-05-23 21:13:01,993] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:13:01,993] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:13:02,006] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.019 seconds
[2022-05-23 21:13:32,252] {processor.py:153} INFO - Started process (PID=1890) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:13:32,252] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:13:32,253] {logging_mixin.py:115} INFO - [2022-05-23 21:13:32,253] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:14:02,253] {logging_mixin.py:115} INFO - [2022-05-23 21:14:02,253] {timeout.py:67} ERROR - Process timed out, PID: 1890
[2022-05-23 21:14:02,254] {logging_mixin.py:115} INFO - [2022-05-23 21:14:02,253] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 1890
[2022-05-23 21:14:02,254] {logging_mixin.py:115} INFO - [2022-05-23 21:14:02,254] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:14:02,255] {logging_mixin.py:115} INFO - [2022-05-23 21:14:02,254] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 1890

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:14:02,255] {logging_mixin.py:115} INFO - [2022-05-23 21:14:02,255] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:14:02,255] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:14:02,267] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.017 seconds
[2022-05-23 21:14:32,525] {processor.py:153} INFO - Started process (PID=2143) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:14:32,525] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:14:32,526] {logging_mixin.py:115} INFO - [2022-05-23 21:14:32,526] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:15:02,527] {logging_mixin.py:115} INFO - [2022-05-23 21:15:02,527] {timeout.py:67} ERROR - Process timed out, PID: 2143
[2022-05-23 21:15:02,527] {logging_mixin.py:115} INFO - [2022-05-23 21:15:02,527] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 2143
[2022-05-23 21:15:02,528] {logging_mixin.py:115} INFO - [2022-05-23 21:15:02,528] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:15:02,528] {logging_mixin.py:115} INFO - [2022-05-23 21:15:02,528] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 2143

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:15:02,528] {logging_mixin.py:115} INFO - [2022-05-23 21:15:02,528] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:15:02,529] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:15:02,564] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.042 seconds
[2022-05-23 21:15:33,225] {processor.py:153} INFO - Started process (PID=2391) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:15:33,227] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:15:33,227] {logging_mixin.py:115} INFO - [2022-05-23 21:15:33,227] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:16:03,228] {logging_mixin.py:115} INFO - [2022-05-23 21:16:03,227] {timeout.py:67} ERROR - Process timed out, PID: 2391
[2022-05-23 21:16:03,228] {logging_mixin.py:115} INFO - [2022-05-23 21:16:03,228] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 2391
[2022-05-23 21:16:03,228] {logging_mixin.py:115} INFO - [2022-05-23 21:16:03,228] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:16:03,229] {logging_mixin.py:115} INFO - [2022-05-23 21:16:03,229] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 2391

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:16:03,230] {logging_mixin.py:115} INFO - [2022-05-23 21:16:03,229] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:16:03,230] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:16:03,244] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.020 seconds
[2022-05-23 21:16:33,544] {processor.py:153} INFO - Started process (PID=2635) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:16:33,545] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:16:33,545] {logging_mixin.py:115} INFO - [2022-05-23 21:16:33,545] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:17:03,546] {logging_mixin.py:115} INFO - [2022-05-23 21:17:03,546] {timeout.py:67} ERROR - Process timed out, PID: 2635
[2022-05-23 21:17:03,547] {logging_mixin.py:115} INFO - [2022-05-23 21:17:03,546] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 2635
[2022-05-23 21:17:03,547] {logging_mixin.py:115} INFO - [2022-05-23 21:17:03,547] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:17:03,547] {logging_mixin.py:115} INFO - [2022-05-23 21:17:03,547] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 2635

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:17:03,548] {logging_mixin.py:115} INFO - [2022-05-23 21:17:03,548] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:17:03,548] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:17:03,559] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.017 seconds
[2022-05-23 21:17:33,997] {processor.py:153} INFO - Started process (PID=2879) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:17:33,998] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:17:33,998] {logging_mixin.py:115} INFO - [2022-05-23 21:17:33,998] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:18:03,999] {logging_mixin.py:115} INFO - [2022-05-23 21:18:03,999] {timeout.py:67} ERROR - Process timed out, PID: 2879
[2022-05-23 21:18:04,000] {logging_mixin.py:115} INFO - [2022-05-23 21:18:03,999] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 2879
[2022-05-23 21:18:04,000] {logging_mixin.py:115} INFO - [2022-05-23 21:18:04,000] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:18:04,000] {logging_mixin.py:115} INFO - [2022-05-23 21:18:04,000] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 2879

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:18:04,001] {logging_mixin.py:115} INFO - [2022-05-23 21:18:04,001] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:18:04,001] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:18:04,013] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.019 seconds
[2022-05-23 21:18:34,405] {processor.py:153} INFO - Started process (PID=3126) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:18:34,406] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:18:34,406] {logging_mixin.py:115} INFO - [2022-05-23 21:18:34,406] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:19:04,407] {logging_mixin.py:115} INFO - [2022-05-23 21:19:04,407] {timeout.py:67} ERROR - Process timed out, PID: 3126
[2022-05-23 21:19:04,408] {logging_mixin.py:115} INFO - [2022-05-23 21:19:04,408] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 3126
[2022-05-23 21:19:04,408] {logging_mixin.py:115} INFO - [2022-05-23 21:19:04,408] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:19:04,409] {logging_mixin.py:115} INFO - [2022-05-23 21:19:04,408] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 3126

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:19:04,409] {logging_mixin.py:115} INFO - [2022-05-23 21:19:04,409] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:19:04,409] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:19:04,421] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.019 seconds
[2022-05-23 21:19:34,578] {processor.py:153} INFO - Started process (PID=3368) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:19:34,578] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:19:34,578] {logging_mixin.py:115} INFO - [2022-05-23 21:19:34,578] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:20:04,580] {logging_mixin.py:115} INFO - [2022-05-23 21:20:04,579] {timeout.py:67} ERROR - Process timed out, PID: 3368
[2022-05-23 21:20:04,582] {logging_mixin.py:115} INFO - [2022-05-23 21:20:04,580] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 3368
[2022-05-23 21:20:04,582] {logging_mixin.py:115} INFO - [2022-05-23 21:20:04,582] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:20:04,584] {logging_mixin.py:115} INFO - [2022-05-23 21:20:04,582] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 3368

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:20:04,585] {logging_mixin.py:115} INFO - [2022-05-23 21:20:04,584] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:20:04,585] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:20:04,618] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.042 seconds
[2022-05-23 21:20:34,829] {processor.py:153} INFO - Started process (PID=3616) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:20:34,830] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:20:34,830] {logging_mixin.py:115} INFO - [2022-05-23 21:20:34,830] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:21:04,832] {logging_mixin.py:115} INFO - [2022-05-23 21:21:04,831] {timeout.py:67} ERROR - Process timed out, PID: 3616
[2022-05-23 21:21:04,833] {logging_mixin.py:115} INFO - [2022-05-23 21:21:04,832] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 3616
[2022-05-23 21:21:04,834] {logging_mixin.py:115} INFO - [2022-05-23 21:21:04,834] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:21:04,835] {logging_mixin.py:115} INFO - [2022-05-23 21:21:04,834] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 3616

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:21:04,836] {logging_mixin.py:115} INFO - [2022-05-23 21:21:04,836] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:21:04,837] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:21:04,863] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.038 seconds
[2022-05-23 21:21:34,971] {processor.py:153} INFO - Started process (PID=3859) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:21:34,971] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:21:34,972] {logging_mixin.py:115} INFO - [2022-05-23 21:21:34,972] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:22:04,973] {logging_mixin.py:115} INFO - [2022-05-23 21:22:04,973] {timeout.py:67} ERROR - Process timed out, PID: 3859
[2022-05-23 21:22:04,975] {logging_mixin.py:115} INFO - [2022-05-23 21:22:04,973] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 3859
[2022-05-23 21:22:04,975] {logging_mixin.py:115} INFO - [2022-05-23 21:22:04,975] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:22:04,977] {logging_mixin.py:115} INFO - [2022-05-23 21:22:04,975] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 3859

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:22:04,978] {logging_mixin.py:115} INFO - [2022-05-23 21:22:04,977] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:22:04,978] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:22:05,003] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.034 seconds
[2022-05-23 21:22:35,101] {processor.py:153} INFO - Started process (PID=4109) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:22:35,101] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:22:35,102] {logging_mixin.py:115} INFO - [2022-05-23 21:22:35,102] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:23:05,103] {logging_mixin.py:115} INFO - [2022-05-23 21:23:05,102] {timeout.py:67} ERROR - Process timed out, PID: 4109
[2022-05-23 21:23:05,105] {logging_mixin.py:115} INFO - [2022-05-23 21:23:05,103] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 4109
[2022-05-23 21:23:05,105] {logging_mixin.py:115} INFO - [2022-05-23 21:23:05,105] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:23:05,106] {logging_mixin.py:115} INFO - [2022-05-23 21:23:05,105] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 4109

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:23:05,107] {logging_mixin.py:115} INFO - [2022-05-23 21:23:05,107] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:23:05,108] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:23:05,133] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.034 seconds
[2022-05-23 21:23:35,246] {processor.py:153} INFO - Started process (PID=4354) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:23:35,247] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:23:35,248] {logging_mixin.py:115} INFO - [2022-05-23 21:23:35,248] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:24:05,249] {logging_mixin.py:115} INFO - [2022-05-23 21:24:05,248] {timeout.py:67} ERROR - Process timed out, PID: 4354
[2022-05-23 21:24:05,251] {logging_mixin.py:115} INFO - [2022-05-23 21:24:05,249] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 4354
[2022-05-23 21:24:05,251] {logging_mixin.py:115} INFO - [2022-05-23 21:24:05,251] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:24:05,252] {logging_mixin.py:115} INFO - [2022-05-23 21:24:05,251] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 4354

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:24:05,253] {logging_mixin.py:115} INFO - [2022-05-23 21:24:05,253] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:24:05,254] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:24:05,281] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.037 seconds
[2022-05-23 21:24:35,468] {processor.py:153} INFO - Started process (PID=4597) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:24:35,469] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:24:35,469] {logging_mixin.py:115} INFO - [2022-05-23 21:24:35,469] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:25:05,470] {logging_mixin.py:115} INFO - [2022-05-23 21:25:05,470] {timeout.py:67} ERROR - Process timed out, PID: 4597
[2022-05-23 21:25:05,472] {logging_mixin.py:115} INFO - [2022-05-23 21:25:05,471] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 4597
[2022-05-23 21:25:05,472] {logging_mixin.py:115} INFO - [2022-05-23 21:25:05,472] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:25:05,474] {logging_mixin.py:115} INFO - [2022-05-23 21:25:05,472] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 4597

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:25:05,475] {logging_mixin.py:115} INFO - [2022-05-23 21:25:05,474] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:25:05,475] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:25:05,493] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.027 seconds
[2022-05-23 21:25:35,607] {processor.py:153} INFO - Started process (PID=4849) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:25:35,608] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:25:35,609] {logging_mixin.py:115} INFO - [2022-05-23 21:25:35,609] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:26:05,610] {logging_mixin.py:115} INFO - [2022-05-23 21:26:05,610] {timeout.py:67} ERROR - Process timed out, PID: 4849
[2022-05-23 21:26:05,612] {logging_mixin.py:115} INFO - [2022-05-23 21:26:05,611] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 4849
[2022-05-23 21:26:05,613] {logging_mixin.py:115} INFO - [2022-05-23 21:26:05,612] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:26:05,614] {logging_mixin.py:115} INFO - [2022-05-23 21:26:05,613] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 4849

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:26:05,615] {logging_mixin.py:115} INFO - [2022-05-23 21:26:05,614] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:26:05,616] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:26:05,646] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.042 seconds
[2022-05-23 21:26:35,842] {processor.py:153} INFO - Started process (PID=5093) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:26:35,844] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:26:35,844] {logging_mixin.py:115} INFO - [2022-05-23 21:26:35,844] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:27:05,846] {logging_mixin.py:115} INFO - [2022-05-23 21:27:05,845] {timeout.py:67} ERROR - Process timed out, PID: 5093
[2022-05-23 21:27:05,847] {logging_mixin.py:115} INFO - [2022-05-23 21:27:05,846] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 5093
[2022-05-23 21:27:05,848] {logging_mixin.py:115} INFO - [2022-05-23 21:27:05,848] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:27:05,849] {logging_mixin.py:115} INFO - [2022-05-23 21:27:05,848] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 5093

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:27:05,851] {logging_mixin.py:115} INFO - [2022-05-23 21:27:05,850] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:27:05,851] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:27:05,877] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.038 seconds
[2022-05-23 21:27:36,004] {processor.py:153} INFO - Started process (PID=5345) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:27:36,005] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:27:36,005] {logging_mixin.py:115} INFO - [2022-05-23 21:27:36,005] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:28:06,007] {logging_mixin.py:115} INFO - [2022-05-23 21:28:06,006] {timeout.py:67} ERROR - Process timed out, PID: 5345
[2022-05-23 21:28:06,008] {logging_mixin.py:115} INFO - [2022-05-23 21:28:06,007] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 5345
[2022-05-23 21:28:06,008] {logging_mixin.py:115} INFO - [2022-05-23 21:28:06,008] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:28:06,009] {logging_mixin.py:115} INFO - [2022-05-23 21:28:06,008] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 5345

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:28:06,010] {logging_mixin.py:115} INFO - [2022-05-23 21:28:06,009] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:28:06,010] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:28:06,022] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.020 seconds
[2022-05-23 21:28:36,196] {processor.py:153} INFO - Started process (PID=5587) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:28:36,198] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:28:36,198] {logging_mixin.py:115} INFO - [2022-05-23 21:28:36,198] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:29:06,199] {logging_mixin.py:115} INFO - [2022-05-23 21:29:06,199] {timeout.py:67} ERROR - Process timed out, PID: 5587
[2022-05-23 21:29:06,201] {logging_mixin.py:115} INFO - [2022-05-23 21:29:06,200] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 5587
[2022-05-23 21:29:06,202] {logging_mixin.py:115} INFO - [2022-05-23 21:29:06,202] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:29:06,203] {logging_mixin.py:115} INFO - [2022-05-23 21:29:06,202] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 5587

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:29:06,204] {logging_mixin.py:115} INFO - [2022-05-23 21:29:06,204] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:29:06,205] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:29:06,234] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.040 seconds
[2022-05-23 21:29:36,403] {processor.py:153} INFO - Started process (PID=5840) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:29:36,404] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:29:36,405] {logging_mixin.py:115} INFO - [2022-05-23 21:29:36,405] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:30:06,406] {logging_mixin.py:115} INFO - [2022-05-23 21:30:06,406] {timeout.py:67} ERROR - Process timed out, PID: 5840
[2022-05-23 21:30:06,408] {logging_mixin.py:115} INFO - [2022-05-23 21:30:06,406] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 5840
[2022-05-23 21:30:06,408] {logging_mixin.py:115} INFO - [2022-05-23 21:30:06,408] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:30:06,410] {logging_mixin.py:115} INFO - [2022-05-23 21:30:06,408] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 5840

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:30:06,411] {logging_mixin.py:115} INFO - [2022-05-23 21:30:06,410] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:30:06,411] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:30:06,437] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.037 seconds
[2022-05-23 21:30:36,654] {processor.py:153} INFO - Started process (PID=6082) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:30:36,655] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:30:36,656] {logging_mixin.py:115} INFO - [2022-05-23 21:30:36,656] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:31:06,657] {logging_mixin.py:115} INFO - [2022-05-23 21:31:06,657] {timeout.py:67} ERROR - Process timed out, PID: 6082
[2022-05-23 21:31:06,659] {logging_mixin.py:115} INFO - [2022-05-23 21:31:06,657] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 6082
[2022-05-23 21:31:06,659] {logging_mixin.py:115} INFO - [2022-05-23 21:31:06,659] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:31:06,661] {logging_mixin.py:115} INFO - [2022-05-23 21:31:06,660] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 6082

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:31:06,662] {logging_mixin.py:115} INFO - [2022-05-23 21:31:06,661] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:31:06,662] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:31:06,681] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.030 seconds
[2022-05-23 21:31:36,874] {processor.py:153} INFO - Started process (PID=6332) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:31:36,875] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:31:36,875] {logging_mixin.py:115} INFO - [2022-05-23 21:31:36,875] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:32:06,876] {logging_mixin.py:115} INFO - [2022-05-23 21:32:06,876] {timeout.py:67} ERROR - Process timed out, PID: 6332
[2022-05-23 21:32:06,878] {logging_mixin.py:115} INFO - [2022-05-23 21:32:06,877] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 6332
[2022-05-23 21:32:06,878] {logging_mixin.py:115} INFO - [2022-05-23 21:32:06,878] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:32:06,880] {logging_mixin.py:115} INFO - [2022-05-23 21:32:06,879] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 6332

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:32:06,881] {logging_mixin.py:115} INFO - [2022-05-23 21:32:06,881] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:32:06,882] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:32:06,909] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.037 seconds
[2022-05-23 21:32:37,130] {processor.py:153} INFO - Started process (PID=6574) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:32:37,131] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:32:37,132] {logging_mixin.py:115} INFO - [2022-05-23 21:32:37,132] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:33:07,133] {logging_mixin.py:115} INFO - [2022-05-23 21:33:07,132] {timeout.py:67} ERROR - Process timed out, PID: 6574
[2022-05-23 21:33:07,134] {logging_mixin.py:115} INFO - [2022-05-23 21:33:07,133] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 6574
[2022-05-23 21:33:07,135] {logging_mixin.py:115} INFO - [2022-05-23 21:33:07,134] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:33:07,136] {logging_mixin.py:115} INFO - [2022-05-23 21:33:07,135] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 6574

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:33:07,137] {logging_mixin.py:115} INFO - [2022-05-23 21:33:07,136] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:33:07,137] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:33:07,154] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.026 seconds
[2022-05-23 21:33:37,459] {processor.py:153} INFO - Started process (PID=6821) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:33:37,460] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:33:37,460] {logging_mixin.py:115} INFO - [2022-05-23 21:33:37,460] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:34:07,461] {logging_mixin.py:115} INFO - [2022-05-23 21:34:07,461] {timeout.py:67} ERROR - Process timed out, PID: 6821
[2022-05-23 21:34:07,462] {logging_mixin.py:115} INFO - [2022-05-23 21:34:07,461] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 6821
[2022-05-23 21:34:07,462] {logging_mixin.py:115} INFO - [2022-05-23 21:34:07,462] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:34:07,463] {logging_mixin.py:115} INFO - [2022-05-23 21:34:07,462] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 6821

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:34:07,464] {logging_mixin.py:115} INFO - [2022-05-23 21:34:07,464] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:34:07,464] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:34:07,480] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.023 seconds
[2022-05-23 21:34:37,650] {processor.py:153} INFO - Started process (PID=7075) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:34:37,651] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:34:37,651] {logging_mixin.py:115} INFO - [2022-05-23 21:34:37,651] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:35:07,652] {logging_mixin.py:115} INFO - [2022-05-23 21:35:07,652] {timeout.py:67} ERROR - Process timed out, PID: 7075
[2022-05-23 21:35:07,652] {logging_mixin.py:115} INFO - [2022-05-23 21:35:07,652] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 7075
[2022-05-23 21:35:07,653] {logging_mixin.py:115} INFO - [2022-05-23 21:35:07,653] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:35:07,653] {logging_mixin.py:115} INFO - [2022-05-23 21:35:07,653] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 7075

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:35:07,653] {logging_mixin.py:115} INFO - [2022-05-23 21:35:07,653] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:35:07,654] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:35:07,666] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.018 seconds
[2022-05-23 21:35:37,890] {processor.py:153} INFO - Started process (PID=7318) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:35:37,890] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:35:37,890] {logging_mixin.py:115} INFO - [2022-05-23 21:35:37,890] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:36:07,891] {logging_mixin.py:115} INFO - [2022-05-23 21:36:07,891] {timeout.py:67} ERROR - Process timed out, PID: 7318
[2022-05-23 21:36:07,893] {logging_mixin.py:115} INFO - [2022-05-23 21:36:07,892] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 7318
[2022-05-23 21:36:07,893] {logging_mixin.py:115} INFO - [2022-05-23 21:36:07,893] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:36:07,895] {logging_mixin.py:115} INFO - [2022-05-23 21:36:07,894] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 7318

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:36:07,896] {logging_mixin.py:115} INFO - [2022-05-23 21:36:07,896] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:36:07,897] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:36:07,918] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.030 seconds
[2022-05-23 21:36:38,339] {processor.py:153} INFO - Started process (PID=7546) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:36:38,341] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:36:38,341] {logging_mixin.py:115} INFO - [2022-05-23 21:36:38,341] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:37:08,342] {logging_mixin.py:115} INFO - [2022-05-23 21:37:08,342] {timeout.py:67} ERROR - Process timed out, PID: 7546
[2022-05-23 21:37:08,343] {logging_mixin.py:115} INFO - [2022-05-23 21:37:08,342] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 7546
[2022-05-23 21:37:08,344] {logging_mixin.py:115} INFO - [2022-05-23 21:37:08,344] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:37:08,345] {logging_mixin.py:115} INFO - [2022-05-23 21:37:08,344] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 7546

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:37:08,345] {logging_mixin.py:115} INFO - [2022-05-23 21:37:08,345] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:37:08,346] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:37:08,361] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.024 seconds
[2022-05-23 21:37:39,128] {processor.py:153} INFO - Started process (PID=7791) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:37:39,128] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:37:39,129] {logging_mixin.py:115} INFO - [2022-05-23 21:37:39,129] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:38:09,129] {logging_mixin.py:115} INFO - [2022-05-23 21:38:09,129] {timeout.py:67} ERROR - Process timed out, PID: 7791
[2022-05-23 21:38:09,130] {logging_mixin.py:115} INFO - [2022-05-23 21:38:09,130] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 7791
[2022-05-23 21:38:09,130] {logging_mixin.py:115} INFO - [2022-05-23 21:38:09,130] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:38:09,131] {logging_mixin.py:115} INFO - [2022-05-23 21:38:09,130] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 7791

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:38:09,131] {logging_mixin.py:115} INFO - [2022-05-23 21:38:09,131] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:38:09,131] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:38:09,153] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.026 seconds
[2022-05-23 21:38:40,113] {processor.py:153} INFO - Started process (PID=8044) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:38:40,114] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:38:40,114] {logging_mixin.py:115} INFO - [2022-05-23 21:38:40,114] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:39:10,116] {logging_mixin.py:115} INFO - [2022-05-23 21:39:10,115] {timeout.py:67} ERROR - Process timed out, PID: 8044
[2022-05-23 21:39:10,117] {logging_mixin.py:115} INFO - [2022-05-23 21:39:10,116] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 8044
[2022-05-23 21:39:10,118] {logging_mixin.py:115} INFO - [2022-05-23 21:39:10,118] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:39:10,119] {logging_mixin.py:115} INFO - [2022-05-23 21:39:10,118] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 8044

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:39:10,120] {logging_mixin.py:115} INFO - [2022-05-23 21:39:10,120] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:39:10,121] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:39:10,152] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.041 seconds
[2022-05-23 21:39:40,866] {processor.py:153} INFO - Started process (PID=8285) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:39:40,867] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:39:40,867] {logging_mixin.py:115} INFO - [2022-05-23 21:39:40,867] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:40:10,868] {logging_mixin.py:115} INFO - [2022-05-23 21:40:10,868] {timeout.py:67} ERROR - Process timed out, PID: 8285
[2022-05-23 21:40:10,869] {logging_mixin.py:115} INFO - [2022-05-23 21:40:10,868] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 8285
[2022-05-23 21:40:10,869] {logging_mixin.py:115} INFO - [2022-05-23 21:40:10,869] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:40:10,869] {logging_mixin.py:115} INFO - [2022-05-23 21:40:10,869] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 8285

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:40:10,870] {logging_mixin.py:115} INFO - [2022-05-23 21:40:10,870] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:40:10,870] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:40:10,883] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.020 seconds
[2022-05-23 21:40:41,640] {processor.py:153} INFO - Started process (PID=8527) to work on /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:40:41,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_jobs/sparksubmit_test.py for tasks to queue
[2022-05-23 21:40:41,640] {logging_mixin.py:115} INFO - [2022-05-23 21:40:41,640] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:41:11,642] {logging_mixin.py:115} INFO - [2022-05-23 21:41:11,641] {timeout.py:67} ERROR - Process timed out, PID: 8527
[2022-05-23 21:41:11,643] {logging_mixin.py:115} INFO - [2022-05-23 21:41:11,642] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 8527
[2022-05-23 21:41:11,643] {logging_mixin.py:115} INFO - [2022-05-23 21:41:11,643] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-05-23 21:41:11,644] {logging_mixin.py:115} INFO - [2022-05-23 21:41:11,643] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_jobs/sparksubmit_test.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.0/best-practices.html#reducing-dag-complexity, PID: 8527

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-05-23 21:41:11,645] {logging_mixin.py:115} INFO - [2022-05-23 21:41:11,645] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_jobs/sparksubmit_test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_jobs/sparksubmit_test.py", line 4, in <module>
    sc = SparkContext("spark://spark-master:7077", "first app")
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-05-23 21:41:11,645] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_jobs/sparksubmit_test.py
[2022-05-23 21:41:11,663] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_jobs/sparksubmit_test.py took 30.025 seconds
